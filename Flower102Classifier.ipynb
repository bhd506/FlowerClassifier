{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Fq5yLR5QlyC"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import scipy.io as scp\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import skimage.io as skio\n",
        "import scipy.io as scp\n",
        "from torch.utils.data import Dataset, DataLoader, Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO6jRqYjRSTQ",
        "outputId": "8eaf89e7-861c-40c4-ef21-f66c57a84bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "le55E2lR9BiR"
      },
      "outputs": [],
      "source": [
        "class CNNBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
        "        super(CNNBlock, self).__init__()\n",
        "        padding = (kernel_size - 1) // 2  # Calculate padding to maintain the same output size\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djv8Mbig7VDn"
      },
      "outputs": [],
      "source": [
        "class MyCNN(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=102):\n",
        "        super(MyCNN, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.layer5 = self._make_layer(block, 512, num_blocks[4], stride=2)\n",
        "        self.layer6 = self._make_layer(block, 512, num_blocks[5], stride=2)\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))  # Ensures output is (1, 1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, 3, stride))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        x = self.layer6(x)\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIt3eH2qaNSs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "DCKbh3EyfBP0"
      },
      "outputs": [],
      "source": [
        "IMAGE_W = 208\n",
        "IMAGE_H = 208\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 100\n",
        "LR = 0.0001\n",
        "\n",
        "# Device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = MyCNN(CNNBlock, [2, 2, 2, 2, 2, 2], num_classes=102)\n",
        "model = model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr = LR)\n",
        "\n",
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "XG8AklkFQriI"
      },
      "outputs": [],
      "source": [
        "flower_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_W, IMAGE_H)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "augmented_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_W, IMAGE_H)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Flip the images randomly with a probability of 0.5\n",
        "    transforms.RandomRotation(15),  # Randomly rotate images in the range (-15, 15) degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Randomly change brightness and contrast\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "root = '/content/drive/MyDrive/ActualFlowers/jpg'\n",
        "\n",
        "train_set = torchvision.datasets.Flowers102(root = root, split = 'train', transform = augmented_transform, target_transform = None, download = False)\n",
        "test_set = torchvision.datasets.Flowers102(root = root, split = 'test', transform = flower_transform, target_transform = None, download = False)\n",
        "validation_set = torchvision.datasets.Flowers102(root = root, split = 'val', transform = flower_transform, target_transform = None, download = False)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_loader = DataLoader(validation_set, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNe-5pZqii5f"
      },
      "outputs": [],
      "source": [
        "def check_accuracy(loader, model, num_classes=102):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Initialize the confusion matrix\n",
        "    confusion_matrix = torch.zeros(num_classes, num_classes, dtype=torch.int64)\n",
        "\n",
        "    with torch.no_grad():  # Do not calculate gradients\n",
        "        for x, y in tqdm.tqdm(loader, desc=\"Evaluating\"):  # Wrap the loader with tqdm\n",
        "            x = x.to(device)  # Move data to the device\n",
        "            y = y.to(device)  # Move labels to the device\n",
        "            scores = model(x)  # Compute model output\n",
        "            _, predictions = scores.max(1)  # Get the predicted classes\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "            # Update confusion matrix\n",
        "            for t, p in zip(y.view(-1), predictions.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "    model.train()  # Set the model back to training mode\n",
        "    accuracy = float(num_correct) / num_samples  # Calculate accuracy\n",
        "\n",
        "    # Print overall accuracy\n",
        "    print(f\"Got {num_correct} / {num_samples} with accuracy {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Return accuracy and confusion matrix for further analysis\n",
        "    return accuracy, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFs1MuFTtmbk"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracy = correct_predictions / len(loader.dataset)\n",
        "    model.train()  # Set the model back to training mode\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npGtwC7pisH7"
      },
      "outputs": [],
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "n_epochs_stop = 10\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    running_loss = 0\n",
        "    with tqdm.tqdm(train_loader, unit='batch') as tepoch:\n",
        "        for index, (x, y) in enumerate(tepoch):\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            y_hat = model(x)\n",
        "            loss = criterion(y_hat, y)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "    #scheduler.step()\n",
        "    # Compute average training loss\n",
        "    avg_training_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch}: Training loss: {running_loss:.4f}\")\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    if epoch >= 10:\n",
        "      validation_loss, validation_accuracy = evaluate(model, validation_loader, device)\n",
        "      print(f\"Epoch {epoch}: Validation loss: {validation_loss:.4f}, Validation accuracy: {validation_accuracy*100:.4f}%\")\n",
        "      # Check for early stopping\n",
        "      if validation_loss < best_val_loss:\n",
        "          best_val_loss = validation_loss\n",
        "          epochs_no_improve = 0\n",
        "          # Save the model if validation loss improves\n",
        "          torch.save(model.state_dict(), 'best_model_v4.pth')\n",
        "      else:\n",
        "          epochs_no_improve += 1\n",
        "          print(f\"No improvement in validation loss for {epochs_no_improve} epochs.\")\n",
        "\n",
        "      # Early stopping condition\n",
        "      if epochs_no_improve == n_epochs_stop and epoch > 30:\n",
        "          print(\"Early stopping triggered\")\n",
        "          break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zQcFoYdg5CA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17faba1d-878b-4bd1-db3b-753801794403"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('best_model_v4.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FTjfYzfIOEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7598d551-87c2-411b-c412-5576bf48c701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 97/97 [01:02<00:00,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 2500 / 6149 with accuracy 40.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4065701740120345,\n",
              " tensor([[ 6,  0,  0,  ...,  0,  0,  0],\n",
              "         [ 0, 23,  0,  ...,  0,  0,  1],\n",
              "         [ 0,  0,  4,  ...,  0,  0,  0],\n",
              "         ...,\n",
              "         [ 0,  0,  0,  ..., 12,  0,  4],\n",
              "         [ 0,  0,  0,  ...,  1,  8,  0],\n",
              "         [ 0,  0,  0,  ...,  0,  0, 21]]))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "check_accuracy(test_loader, model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}