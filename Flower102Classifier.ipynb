{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Obd7eBTQXhPa"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import scipy.io as scp\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import skimage.io as skio\n",
        "import scipy.io as scp\n",
        "from torch.utils.data import Dataset, DataLoader, Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCZ8TtYqXs05",
        "outputId": "31f66295-346d-42ca-c824-e78acf06c469"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eC_qpXlcYT3M"
      },
      "outputs": [],
      "source": [
        "class MyCNN(nn.Module):\n",
        "  def __init__(self, num_channels, num_out_ch, img_w, img_h, num_classes):\n",
        "    super(MyCNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=num_out_ch[0],\n",
        "                           kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "    self.bn1 = nn.BatchNorm2d(num_out_ch[0])\n",
        "    self.conv2 = nn.Conv2d(in_channels=num_out_ch[0], out_channels=num_out_ch[1],\n",
        "                           kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "    self.bn2 = nn.BatchNorm2d(num_out_ch[1])\n",
        "    self.conv3 = nn.Conv2d(in_channels=num_out_ch[1], out_channels=num_out_ch[1],\n",
        "                           kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "    self.bn3 = nn.BatchNorm2d(num_out_ch[1])\n",
        "    self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "    self.fc = nn.Linear(in_features = int(img_w//4)*int(img_h//4)*num_out_ch[1], out_features=num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.fc(x.reshape(x.shape[0], -1))\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zSk60TWY3Bf"
      },
      "outputs": [],
      "source": [
        "NUM_OUT_CH = [8, 16]\n",
        "IMAGE_W = 208\n",
        "IMAGE_H = 208\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 12\n",
        "LR = 0.001\n",
        "\n",
        "# Device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# model\n",
        "model = MyCNN(num_channels=3, num_out_ch=NUM_OUT_CH, img_w=IMAGE_W, img_h=IMAGE_H, num_classes=102)\n",
        "model = model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr = LR)\n",
        "\n",
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uq-ObF9ZIPI"
      },
      "outputs": [],
      "source": [
        "flower_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_W, IMAGE_H)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "augmented_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_W, IMAGE_H)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Flip the images randomly with a probability of 0.5\n",
        "    transforms.RandomRotation(15),  # Randomly rotate images in the range (-15, 15) degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Randomly change brightness and contrast\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "root = '/content/drive/MyDrive/ActualFlowers/jpg'\n",
        "\n",
        "train_set = torchvision.datasets.Flowers102(root = root, split = 'train', transform = augmented_transform, target_transform = None, download = False)\n",
        "test_set = torchvision.datasets.Flowers102(root = root, split = 'test', transform = flower_transform, target_transform = None, download = False)\n",
        "validation_set = torchvision.datasets.Flowers102(root = root, split = 'val', transform = flower_transform, target_transform = None, download = False)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_loader = DataLoader(validation_set, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0qmb50uY8ZA"
      },
      "outputs": [],
      "source": [
        "def check_accuracy(loader, model, num_classes=102):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Initialize the confusion matrix\n",
        "    confusion_matrix = torch.zeros(num_classes, num_classes, dtype=torch.int64)\n",
        "\n",
        "    with torch.no_grad():  # Do not calculate gradients\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)  # Move data to the device\n",
        "            y = y.to(device)  # Move labels to the device\n",
        "            scores = model(x)  # Compute model output\n",
        "            _, predictions = scores.max(1)  # Get the predicted classes\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "            # Update confusion matrix\n",
        "            for t, p in zip(y.view(-1), predictions.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "    model.train()  # Set the model back to training mode\n",
        "    accuracy = float(num_correct) / num_samples  # Calculate accuracy\n",
        "\n",
        "    # Print overall accuracy\n",
        "    print(f\"Got {num_correct} / {num_samples} with accuracy {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Print confusion matrix or other statistics if necessary\n",
        "    # For detailed analysis, you might return or further process the confusion matrix\n",
        "    return accuracy, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uln6No72ZSuu"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracy = correct_predictions / len(loader.dataset)\n",
        "    model.train()  # Set the model back to training mode\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "balxC9BhZWrr",
        "outputId": "12eea9dd-e8e0-45f8-a541-9dea38f01558"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [07:41<00:00, 28.85s/batch, loss=4.58]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Training loss: 122.1905\n",
            "Got 309 / 6149 with accuracy 5.03%\n",
            "Epoch 0: Validation loss: 4.7011, Validation accuracy: 4.3137%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:41<00:00,  2.57s/batch, loss=4.03]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Training loss: 68.6738\n",
            "Got 317 / 6149 with accuracy 5.16%\n",
            "Epoch 1: Validation loss: 4.1064, Validation accuracy: 6.7647%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:38<00:00,  2.42s/batch, loss=3.32]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: Training loss: 56.8994\n",
            "Got 822 / 6149 with accuracy 13.37%\n",
            "Epoch 2: Validation loss: 3.7121, Validation accuracy: 15.4902%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:39<00:00,  2.46s/batch, loss=2.85]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: Training loss: 45.2280\n",
            "Got 1087 / 6149 with accuracy 17.68%\n",
            "Epoch 3: Validation loss: 3.6359, Validation accuracy: 18.2353%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:39<00:00,  2.48s/batch, loss=1.84]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: Training loss: 34.9709\n",
            "Got 1115 / 6149 with accuracy 18.13%\n",
            "Epoch 4: Validation loss: 3.5877, Validation accuracy: 23.3333%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:38<00:00,  2.43s/batch, loss=1.95]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: Training loss: 27.5707\n",
            "Got 1302 / 6149 with accuracy 21.17%\n",
            "Epoch 5: Validation loss: 3.6557, Validation accuracy: 23.8235%\n",
            "No improvement in validation loss for 1 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:39<00:00,  2.47s/batch, loss=1.28]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: Training loss: 23.5267\n",
            "Got 1412 / 6149 with accuracy 22.96%\n",
            "Epoch 6: Validation loss: 3.6016, Validation accuracy: 26.4706%\n",
            "No improvement in validation loss for 2 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:39<00:00,  2.47s/batch, loss=1.32]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: Training loss: 18.6255\n",
            "Got 1438 / 6149 with accuracy 23.39%\n",
            "Epoch 7: Validation loss: 3.7377, Validation accuracy: 25.2941%\n",
            "No improvement in validation loss for 3 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:40<00:00,  2.51s/batch, loss=1.14]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: Training loss: 15.4998\n",
            "Got 1414 / 6149 with accuracy 23.00%\n",
            "Epoch 8: Validation loss: 3.8837, Validation accuracy: 26.2745%\n",
            "No improvement in validation loss for 4 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:38<00:00,  2.40s/batch, loss=0.506]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: Training loss: 12.4785\n",
            "Got 1458 / 6149 with accuracy 23.71%\n",
            "Epoch 9: Validation loss: 3.8897, Validation accuracy: 25.8824%\n",
            "No improvement in validation loss for 5 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:39<00:00,  2.44s/batch, loss=0.62]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: Training loss: 11.1168\n",
            "Got 1598 / 6149 with accuracy 25.99%\n",
            "Epoch 10: Validation loss: 3.9947, Validation accuracy: 26.7647%\n",
            "No improvement in validation loss for 6 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:38<00:00,  2.43s/batch, loss=0.511]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Training loss: 8.6819\n",
            "Got 1568 / 6149 with accuracy 25.50%\n",
            "Epoch 11: Validation loss: 3.9561, Validation accuracy: 29.8039%\n",
            "No improvement in validation loss for 7 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:37<00:00,  2.36s/batch, loss=0.548]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Training loss: 7.7666\n",
            "Got 1650 / 6149 with accuracy 26.83%\n",
            "Epoch 12: Validation loss: 4.1908, Validation accuracy: 30.0980%\n",
            "No improvement in validation loss for 8 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:40<00:00,  2.50s/batch, loss=0.657]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Training loss: 6.8661\n",
            "Got 1527 / 6149 with accuracy 24.83%\n",
            "Epoch 13: Validation loss: 4.2688, Validation accuracy: 27.9412%\n",
            "No improvement in validation loss for 9 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:40<00:00,  2.53s/batch, loss=0.233]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: Training loss: 6.0672\n",
            "Got 1614 / 6149 with accuracy 26.25%\n",
            "Epoch 14: Validation loss: 4.5203, Validation accuracy: 27.6471%\n",
            "No improvement in validation loss for 10 epochs.\n",
            "Early stopping triggered\n"
          ]
        }
      ],
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "n_epochs_stop = 10\n",
        "for epoch in range(NUM_EPOCHS*5):\n",
        "    running_loss = 0\n",
        "    with tqdm.tqdm(train_loader, unit='batch') as tepoch:\n",
        "        for index, (x, y) in enumerate(tepoch):\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            y_hat = model(x)\n",
        "            loss = criterion(y_hat, y)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Compute average training loss\n",
        "    avg_training_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch}: Training loss: {running_loss:.4f}\")\n",
        "    check_accuracy(test_loader, model)\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    validation_loss, validation_accuracy = evaluate(model, validation_loader, device)\n",
        "    print(f\"Epoch {epoch}: Validation loss: {validation_loss:.4f}, Validation accuracy: {validation_accuracy*100:.4f}%\")\n",
        "\n",
        "    # Check for early stopping\n",
        "    if validation_loss < best_val_loss:\n",
        "        best_val_loss = validation_loss\n",
        "        epochs_no_improve = 0\n",
        "        # Save the model if validation loss improves\n",
        "        torch.save(model.state_dict(), 'best_model_v1.pth')\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"No improvement in validation loss for {epochs_no_improve} epochs.\")\n",
        "\n",
        "    # Early stopping condition\n",
        "    if epochs_no_improve == n_epochs_stop:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}