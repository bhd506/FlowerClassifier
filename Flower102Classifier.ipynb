{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Obd7eBTQXhPa"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import scipy.io as scp\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import skimage.io as skio\n",
        "import scipy.io as scp\n",
        "from torch.utils.data import Dataset, DataLoader, Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCZ8TtYqXs05",
        "outputId": "31f66295-346d-42ca-c824-e78acf06c469"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eC_qpXlcYT3M"
      },
      "outputs": [],
      "source": [
        "class MyCNN(nn.Module):\n",
        "  def __init__(self, num_channels, num_out_ch, img_w, img_h, num_classes):\n",
        "    super(MyCNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=num_out_ch[0],\n",
        "                           kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "    self.bn1 = nn.BatchNorm2d(num_out_ch[0])\n",
        "    self.conv2 = nn.Conv2d(in_channels=num_out_ch[0], out_channels=num_out_ch[1],\n",
        "                           kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "    self.bn2 = nn.BatchNorm2d(num_out_ch[1])\n",
        "    self.conv3 = nn.Conv2d(in_channels=num_out_ch[1], out_channels=num_out_ch[1],\n",
        "                           kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "    self.bn3 = nn.BatchNorm2d(num_out_ch[1])\n",
        "    self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "    self.fc = nn.Linear(in_features = int(img_w//4)*int(img_h//4)*num_out_ch[1], out_features=num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.fc(x.reshape(x.shape[0], -1))\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zSk60TWY3Bf"
      },
      "outputs": [],
      "source": [
        "NUM_OUT_CH = [8, 16]\n",
        "IMAGE_W = 208\n",
        "IMAGE_H = 208\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 12\n",
        "LR = 0.001\n",
        "\n",
        "# Device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# model\n",
        "model = MyCNN(num_channels=3, num_out_ch=NUM_OUT_CH, img_w=IMAGE_W, img_h=IMAGE_H, num_classes=102)\n",
        "model = model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr = LR)\n",
        "\n",
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uq-ObF9ZIPI"
      },
      "outputs": [],
      "source": [
        "flower_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_W, IMAGE_H)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "augmented_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_W, IMAGE_H)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Flip the images randomly with a probability of 0.5\n",
        "    transforms.RandomRotation(15),  # Randomly rotate images in the range (-15, 15) degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Randomly change brightness and contrast\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "root = '/content/drive/MyDrive/ActualFlowers/jpg'\n",
        "\n",
        "train_set = torchvision.datasets.Flowers102(root = root, split = 'train', transform = augmented_transform, target_transform = None, download = False)\n",
        "test_set = torchvision.datasets.Flowers102(root = root, split = 'test', transform = flower_transform, target_transform = None, download = False)\n",
        "validation_set = torchvision.datasets.Flowers102(root = root, split = 'val', transform = flower_transform, target_transform = None, download = False)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_loader = DataLoader(validation_set, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0qmb50uY8ZA"
      },
      "outputs": [],
      "source": [
        "def check_accuracy(loader, model, num_classes=102):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Initialize the confusion matrix\n",
        "    confusion_matrix = torch.zeros(num_classes, num_classes, dtype=torch.int64)\n",
        "\n",
        "    with torch.no_grad():  # Do not calculate gradients\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)  # Move data to the device\n",
        "            y = y.to(device)  # Move labels to the device\n",
        "            scores = model(x)  # Compute model output\n",
        "            _, predictions = scores.max(1)  # Get the predicted classes\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "            # Update confusion matrix\n",
        "            for t, p in zip(y.view(-1), predictions.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "    model.train()  # Set the model back to training mode\n",
        "    accuracy = float(num_correct) / num_samples  # Calculate accuracy\n",
        "\n",
        "    # Print overall accuracy\n",
        "    print(f\"Got {num_correct} / {num_samples} with accuracy {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Print confusion matrix or other statistics if necessary\n",
        "    # For detailed analysis, you might return or further process the confusion matrix\n",
        "    return accuracy, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uln6No72ZSuu"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracy = correct_predictions / len(loader.dataset)\n",
        "    model.train()  # Set the model back to training mode\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "balxC9BhZWrr",
        "outputId": "826c37be-f630-4cc1-a38c-cfe92cf47b41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:30<00:00,  1.06batch/s, loss=4.47]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Training loss: 167.4602\n",
            "Got 402 / 6149 with accuracy 6.54%\n",
            "Epoch 0: Validation loss: 4.1430, Validation accuracy: 6.2745%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:30<00:00,  1.06batch/s, loss=3.68]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Training loss: 111.1782\n",
            "Got 818 / 6149 with accuracy 13.30%\n",
            "Epoch 1: Validation loss: 3.6784, Validation accuracy: 17.6471%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:34<00:00,  1.07s/batch, loss=2.46]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: Training loss: 81.7712\n",
            "Got 1196 / 6149 with accuracy 19.45%\n",
            "Epoch 2: Validation loss: 3.5814, Validation accuracy: 20.5882%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:32<00:00,  1.02s/batch, loss=1.71]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: Training loss: 61.3200\n",
            "Got 1167 / 6149 with accuracy 18.98%\n",
            "Epoch 3: Validation loss: 3.5712, Validation accuracy: 21.9608%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:32<00:00,  1.00s/batch, loss=1.2]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: Training loss: 47.3487\n",
            "Got 1333 / 6149 with accuracy 21.68%\n",
            "Epoch 4: Validation loss: 3.6351, Validation accuracy: 24.0196%\n",
            "No improvement in validation loss for 1 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:31<00:00,  1.03batch/s, loss=1.52]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: Training loss: 36.3939\n",
            "Got 1435 / 6149 with accuracy 23.34%\n",
            "Epoch 5: Validation loss: 3.7416, Validation accuracy: 27.3529%\n",
            "No improvement in validation loss for 2 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:31<00:00,  1.01batch/s, loss=0.882]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: Training loss: 29.8060\n",
            "Got 1500 / 6149 with accuracy 24.39%\n",
            "Epoch 6: Validation loss: 3.8561, Validation accuracy: 27.7451%\n",
            "No improvement in validation loss for 3 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:31<00:00,  1.03batch/s, loss=0.745]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: Training loss: 24.7078\n",
            "Got 1462 / 6149 with accuracy 23.78%\n",
            "Epoch 7: Validation loss: 4.0077, Validation accuracy: 28.8235%\n",
            "No improvement in validation loss for 4 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:31<00:00,  1.02batch/s, loss=0.636]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: Training loss: 19.3282\n",
            "Got 1444 / 6149 with accuracy 23.48%\n",
            "Epoch 8: Validation loss: 4.2963, Validation accuracy: 26.9608%\n",
            "No improvement in validation loss for 5 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:30<00:00,  1.05batch/s, loss=0.729]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: Training loss: 16.6770\n",
            "Got 1531 / 6149 with accuracy 24.90%\n",
            "Epoch 9: Validation loss: 4.1281, Validation accuracy: 27.9412%\n",
            "No improvement in validation loss for 6 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:31<00:00,  1.02batch/s, loss=0.395]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: Training loss: 13.2232\n",
            "Got 1477 / 6149 with accuracy 24.02%\n",
            "Epoch 10: Validation loss: 4.3940, Validation accuracy: 28.0392%\n",
            "No improvement in validation loss for 7 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:31<00:00,  1.03batch/s, loss=0.274]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Training loss: 11.6304\n",
            "Got 1425 / 6149 with accuracy 23.17%\n",
            "Epoch 11: Validation loss: 4.7607, Validation accuracy: 27.5490%\n",
            "No improvement in validation loss for 8 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:32<00:00,  1.03s/batch, loss=0.352]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Training loss: 11.3056\n",
            "Got 1470 / 6149 with accuracy 23.91%\n",
            "Epoch 12: Validation loss: 4.6099, Validation accuracy: 28.2353%\n",
            "No improvement in validation loss for 9 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:32<00:00,  1.02s/batch, loss=0.621]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Training loss: 9.1760\n",
            "Got 1564 / 6149 with accuracy 25.44%\n",
            "Epoch 13: Validation loss: 4.5240, Validation accuracy: 30.5882%\n",
            "No improvement in validation loss for 10 epochs.\n",
            "Early stopping triggered\n"
          ]
        }
      ],
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "n_epochs_stop = 10\n",
        "for epoch in range(NUM_EPOCHS*5):\n",
        "    running_loss = 0\n",
        "    with tqdm.tqdm(train_loader, unit='batch') as tepoch:\n",
        "        for index, (x, y) in enumerate(tepoch):\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            y_hat = model(x)\n",
        "            loss = criterion(y_hat, y)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Compute average training loss\n",
        "    avg_training_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch}: Training loss: {running_loss:.4f}\")\n",
        "    check_accuracy(test_loader, model)\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    validation_loss, validation_accuracy = evaluate(model, validation_loader, device)\n",
        "    print(f\"Epoch {epoch}: Validation loss: {validation_loss:.4f}, Validation accuracy: {validation_accuracy*100:.4f}%\")\n",
        "\n",
        "    # Check for early stopping\n",
        "    if validation_loss < best_val_loss:\n",
        "        best_val_loss = validation_loss\n",
        "        epochs_no_improve = 0\n",
        "        # Save the model if validation loss improves\n",
        "        torch.save(model.state_dict(), 'best_model_v1.pth')\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"No improvement in validation loss for {epochs_no_improve} epochs.\")\n",
        "\n",
        "    # Early stopping condition\n",
        "    if epochs_no_improve == n_epochs_stop:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}