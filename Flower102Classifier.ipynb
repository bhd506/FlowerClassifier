{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Obd7eBTQXhPa"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import scipy.io as scp\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import skimage.io as skio\n",
        "import scipy.io as scp\n",
        "from torch.utils.data import Dataset, DataLoader, Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCZ8TtYqXs05",
        "outputId": "ef930735-15ae-4adc-b8fc-daaa27c2a805"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eC_qpXlcYT3M"
      },
      "outputs": [],
      "source": [
        "class MyCNN(nn.Module):\n",
        "  def __init__(self, num_channels, num_out_ch, img_w, img_h, num_classes):\n",
        "    super(MyCNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=num_out_ch[0],\n",
        "                           kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "    self.bn1 = nn.BatchNorm2d(num_out_ch[0])\n",
        "    self.conv2 = nn.Conv2d(in_channels=num_out_ch[0], out_channels=num_out_ch[1],\n",
        "                           kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "    self.bn2 = nn.BatchNorm2d(num_out_ch[1])\n",
        "    self.conv3 = nn.Conv2d(in_channels=num_out_ch[1], out_channels=num_out_ch[1],\n",
        "                           kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "    self.bn3 = nn.BatchNorm2d(num_out_ch[1])\n",
        "    self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "    self.fc = nn.Linear(in_features = int(img_w//4)*int(img_h//4)*num_out_ch[1], out_features=num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.fc(x.reshape(x.shape[0], -1))\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zSk60TWY3Bf"
      },
      "outputs": [],
      "source": [
        "NUM_OUT_CH = [8, 16]\n",
        "IMAGE_W = 208\n",
        "IMAGE_H = 208\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 12\n",
        "LR = 0.0001\n",
        "\n",
        "# Device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# model\n",
        "model = MyCNN(num_channels=3, num_out_ch=NUM_OUT_CH, img_w=IMAGE_W, img_h=IMAGE_H, num_classes=102)\n",
        "model = model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr = LR)\n",
        "\n",
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uq-ObF9ZIPI"
      },
      "outputs": [],
      "source": [
        "flower_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_W, IMAGE_H)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "augmented_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_W, IMAGE_H)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Flip the images randomly with a probability of 0.5\n",
        "    transforms.RandomRotation(15),  # Randomly rotate images in the range (-15, 15) degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Randomly change brightness and contrast\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "root = '/content/drive/MyDrive/ActualFlowers/jpg'\n",
        "\n",
        "train_set = torchvision.datasets.Flowers102(root = root, split = 'train', transform = augmented_transform, target_transform = None, download = False)\n",
        "test_set = torchvision.datasets.Flowers102(root = root, split = 'test', transform = flower_transform, target_transform = None, download = False)\n",
        "validation_set = torchvision.datasets.Flowers102(root = root, split = 'val', transform = flower_transform, target_transform = None, download = False)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_loader = DataLoader(validation_set, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0qmb50uY8ZA"
      },
      "outputs": [],
      "source": [
        "def check_accuracy(loader, model, num_classes=102):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Initialize the confusion matrix\n",
        "    confusion_matrix = torch.zeros(num_classes, num_classes, dtype=torch.int64)\n",
        "\n",
        "    with torch.no_grad():  # Do not calculate gradients\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)  # Move data to the device\n",
        "            y = y.to(device)  # Move labels to the device\n",
        "            scores = model(x)  # Compute model output\n",
        "            _, predictions = scores.max(1)  # Get the predicted classes\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "            # Update confusion matrix\n",
        "            for t, p in zip(y.view(-1), predictions.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "    model.train()  # Set the model back to training mode\n",
        "    accuracy = float(num_correct) / num_samples  # Calculate accuracy\n",
        "\n",
        "    # Print overall accuracy\n",
        "    print(f\"Got {num_correct} / {num_samples} with accuracy {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Print confusion matrix or other statistics if necessary\n",
        "    # For detailed analysis, you might return or further process the confusion matrix\n",
        "    return accuracy, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uln6No72ZSuu"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracy = correct_predictions / len(loader.dataset)\n",
        "    model.train()  # Set the model back to training mode\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "balxC9BhZWrr",
        "outputId": "ccf8b199-20a5-4f3b-c991-e50920d75689"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [07:37<00:00, 28.61s/batch, loss=4.46]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Training loss: 74.1644\n",
            "Got 356 / 6149 with accuracy 5.79%\n",
            "Epoch 0: Validation loss: 4.2867, Validation accuracy: 8.0392%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:34<00:00,  2.16s/batch, loss=3.83]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Training loss: 65.2721\n",
            "Got 691 / 6149 with accuracy 11.24%\n",
            "Epoch 1: Validation loss: 4.0065, Validation accuracy: 13.4314%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:34<00:00,  2.18s/batch, loss=3.74]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: Training loss: 58.8879\n",
            "Got 734 / 6149 with accuracy 11.94%\n",
            "Epoch 2: Validation loss: 3.7662, Validation accuracy: 16.2745%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:35<00:00,  2.20s/batch, loss=3.06]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: Training loss: 53.1633\n",
            "Got 887 / 6149 with accuracy 14.43%\n",
            "Epoch 3: Validation loss: 3.6099, Validation accuracy: 20.0980%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:34<00:00,  2.15s/batch, loss=2.76]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: Training loss: 47.4219\n",
            "Got 977 / 6149 with accuracy 15.89%\n",
            "Epoch 4: Validation loss: 3.4881, Validation accuracy: 20.6863%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:34<00:00,  2.15s/batch, loss=2.75]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: Training loss: 43.5895\n",
            "Got 1026 / 6149 with accuracy 16.69%\n",
            "Epoch 5: Validation loss: 3.4124, Validation accuracy: 21.3725%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:35<00:00,  2.21s/batch, loss=2.58]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: Training loss: 38.5912\n",
            "Got 1054 / 6149 with accuracy 17.14%\n",
            "Epoch 6: Validation loss: 3.3961, Validation accuracy: 22.6471%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:34<00:00,  2.17s/batch, loss=1.99]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: Training loss: 35.7524\n",
            "Got 1172 / 6149 with accuracy 19.06%\n",
            "Epoch 7: Validation loss: 3.3636, Validation accuracy: 21.8627%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:34<00:00,  2.17s/batch, loss=1.89]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: Training loss: 32.2029\n",
            "Got 1124 / 6149 with accuracy 18.28%\n",
            "Epoch 8: Validation loss: 3.3726, Validation accuracy: 23.7255%\n",
            "No improvement in validation loss for 1 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:35<00:00,  2.21s/batch, loss=1.79]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: Training loss: 29.3869\n",
            "Got 1227 / 6149 with accuracy 19.95%\n",
            "Epoch 9: Validation loss: 3.4107, Validation accuracy: 22.9412%\n",
            "No improvement in validation loss for 2 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:35<00:00,  2.20s/batch, loss=1.5]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: Training loss: 27.0425\n",
            "Got 1221 / 6149 with accuracy 19.86%\n",
            "Epoch 10: Validation loss: 3.3980, Validation accuracy: 24.2157%\n",
            "No improvement in validation loss for 3 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:35<00:00,  2.20s/batch, loss=1.46]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Training loss: 24.6541\n",
            "Got 1242 / 6149 with accuracy 20.20%\n",
            "Epoch 11: Validation loss: 3.4404, Validation accuracy: 25.1961%\n",
            "No improvement in validation loss for 4 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:34<00:00,  2.13s/batch, loss=1.4]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Training loss: 22.6827\n",
            "Got 1297 / 6149 with accuracy 21.09%\n",
            "Epoch 12: Validation loss: 3.4905, Validation accuracy: 22.7451%\n",
            "No improvement in validation loss for 5 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:35<00:00,  2.20s/batch, loss=1.37]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Training loss: 21.2602\n",
            "Got 1308 / 6149 with accuracy 21.27%\n",
            "Epoch 13: Validation loss: 3.5106, Validation accuracy: 24.2157%\n",
            "No improvement in validation loss for 6 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:34<00:00,  2.14s/batch, loss=1.28]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: Training loss: 19.5887\n",
            "Got 1253 / 6149 with accuracy 20.38%\n",
            "Epoch 14: Validation loss: 3.5231, Validation accuracy: 24.8039%\n",
            "No improvement in validation loss for 7 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:36<00:00,  2.27s/batch, loss=1.25]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15: Training loss: 18.9143\n",
            "Got 1357 / 6149 with accuracy 22.07%\n",
            "Epoch 15: Validation loss: 3.5429, Validation accuracy: 24.8039%\n",
            "No improvement in validation loss for 8 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:37<00:00,  2.33s/batch, loss=1.19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: Training loss: 16.6835\n",
            "Got 1255 / 6149 with accuracy 20.41%\n",
            "Epoch 16: Validation loss: 3.6413, Validation accuracy: 24.6078%\n",
            "No improvement in validation loss for 9 epochs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:35<00:00,  2.20s/batch, loss=0.852]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: Training loss: 15.4820\n",
            "Got 1262 / 6149 with accuracy 20.52%\n",
            "Epoch 17: Validation loss: 3.6669, Validation accuracy: 24.6078%\n",
            "No improvement in validation loss for 10 epochs.\n",
            "Early stopping triggered\n"
          ]
        }
      ],
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "n_epochs_stop = 10\n",
        "for epoch in range(NUM_EPOCHS*5):\n",
        "    running_loss = 0\n",
        "    with tqdm.tqdm(train_loader, unit='batch') as tepoch:\n",
        "        for index, (x, y) in enumerate(tepoch):\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            y_hat = model(x)\n",
        "            loss = criterion(y_hat, y)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Compute average training loss\n",
        "    avg_training_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch}: Training loss: {running_loss:.4f}\")\n",
        "    check_accuracy(test_loader, model)\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    validation_loss, validation_accuracy = evaluate(model, validation_loader, device)\n",
        "    print(f\"Epoch {epoch}: Validation loss: {validation_loss:.4f}, Validation accuracy: {validation_accuracy*100:.4f}%\")\n",
        "\n",
        "    # Check for early stopping\n",
        "    if validation_loss < best_val_loss:\n",
        "        best_val_loss = validation_loss\n",
        "        epochs_no_improve = 0\n",
        "        # Save the model if validation loss improves\n",
        "        torch.save(model.state_dict(), 'best_model_v1.pth')\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"No improvement in validation loss for {epochs_no_improve} epochs.\")\n",
        "\n",
        "    # Early stopping condition\n",
        "    if epochs_no_improve == n_epochs_stop:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}